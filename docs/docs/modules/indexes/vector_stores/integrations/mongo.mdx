# Mongo

Langchain supports MongoDB Atlas. It is important to note that due to the requirement of Atlas-only indexes it is not possible to use a local or self-hosted MongoDB instance, only the Atlas cloud service. Refer to the [Atlas Search documentation](https://www.mongodb.com/docs/atlas/atlas-search/) for more information.

## Setup

### Installation

```bash npm2yarn
npm install -S mongodb
```

### Database Configuration

The recommended way to do this is to manually create the collection and add the index. It is possible to let the mongo driver create the collection, however the index will still need to be created manually.

#### Index Creation

To create the index first navigate to the project in the atlas ui.

Next select `Search` from the left hand menu.

Select your cluster and proceed to the create index wizard.

Using the json editor add the following index to the collection you wish to use. The `dimension` field should match the dimensions of the vector you wish to store. At the time of writing this documentation doing this through the visual editor is not possible.

**Note:** OpenAI embeddings are to large in dimensionality for Atlas coming in at 1536. However, the Cohere embeddings are perfectly usable with a dimensionality of 1024. (See [limitations](#limitations).)

```json
{
  "mappings": {
    "fields": {
      "embedding": [
        {
          "dimensions": 1024,
          "similarity": "euclidean",
          "type": "knnVector"
        }
      ]
    }
  }
}
```

By default the vector store expect an index name of `default` although the configuration options allow this name to be arbitrary.

Finally, proceed to build the index.

## Usage

### Ingestion

import CodeBlock from "@theme/CodeBlock";
import Ingestion from "@examples/indexes/vector_stores/mongo_fromTexts.ts";

<CodeBlock language="typescript">{Ingestion}</CodeBlock>

### Search

import Search from "@examples/indexes/vector_stores/mongo_search.ts";

<CodeBlock language="typescript">{Search}</CodeBlock>

## Limitations

Internally atlas uses Apache Lucene. This limits the dimensionality of the the vector index to 1024. This limit may be raised in the future, see [this issue](https://github.com/apache/lucene/pull/12191) to follow the ongoing discussion.

Another pitfall is indexing completion time. Documents inserted into the collection are not immediately indexed. Right now there is no way to know the status of the indexing process using just langchain. If your project needs this functionality you can access it by using the [Atlas API](https://www.mongodb.com/docs/atlas/reference/api-resources-spec/#tag/Atlas-Search) however at the current time this is outside of the scope of langchain.

Adding additional pipeline stages must be done [after the knn search](https://www.mongodb.com/docs/atlas/atlas-search/query-syntax/#behavior). This severely limits both the usefulness of adding additional filters as well hampering performance. Nevertheless it is possible by passing a filter object to search methods.

```typescript
const filter: MongoVectorStoreQueryExtension = {
  postQueryPipelineSteps: [
    {
      $match: {
        "metadata.some_field": { $gte: 5 },
      },
    },
  ],
};

const filteredResults = await vectorStore.similaritySearch(
  "Some query text",
  4,
  filter
);
```
